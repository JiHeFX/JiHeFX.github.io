<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LLM应用（二）：知识层面的漏洞检测RAG</title>
      <link href="/2025/03/26/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%9F%A5%E8%AF%86%E5%B1%82%E9%9D%A2%E7%9A%84%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8BRAG/"/>
      <url>/2025/03/26/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%9F%A5%E8%AF%86%E5%B1%82%E9%9D%A2%E7%9A%84%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8BRAG/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>论文名称：Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG</p><h2 id="系统框架">系统框架</h2><h2 id="准备工作">准备工作</h2><h3 id="漏洞分类系统">漏洞分类系统</h3><p>现有的漏洞分类系统，如CVE和CWE，提供了对漏洞的全面分类和管理体系。</p><ul><li><p>CVE（Common Vulnerabilities and Exposures）漏洞用于描述和标识信息安全领域的已知漏洞和安全风险。CVE是一个公开的列表或数据库，它为各种公开知晓的信息安全漏洞和风险提供了标准化的名称。每个CVE标识符都是唯一的，并按照一定的格式命名。这些标识符允许安全专家和研究人员在讨论、分析或修复特定的漏洞时保持一致性。</p></li><li><p>CWE（CommonWeakness Enumeration）是一个公开可访问的常见软件和硬件安全漏洞分类系统。每种弱点类型都有一个唯一的标识符（CWE ID）。虽然CWE提供了漏洞类型的广泛分类，但在给定CWE类别下导致漏洞的具体代码行为可能会有很大的差异。例如，CWE-416（Use After Free）表示在内存被释放后仍然引用该内存的问题。该漏洞的根本原因可能来源于竞争条件下的不当同步（例如CVE-2023-30772），或由于引用计数错误导致对象过早销毁（例如CVE-2023-3609）。</p></li></ul><p>CWE涉及软件安全缺陷的方方面面。基本上可以认为CWE是所有漏洞的原理基础性总结分析，CVE中相当数量的漏洞的成因在CWE中都可以找到相应的条目。如在代码层、应用层等多个方面的缺陷，从CWE角度看，正是由于CWE的一个或多个缺陷，从而形成了CVE的漏洞。</p><h3 id="性能测试基准数据库">性能测试基准数据库</h3><p>以漏洞代码与修复代码为一对进行构建。<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%9F%A5%E8%AF%86%E5%B1%82%E9%9D%A2%E7%9A%84%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8BRAG/codepair.png" alt="error"></p><p>格式：</p><ul><li>CVE ID: 漏洞在CVE中的唯一标识。</li><li>CVE Description: Descriptions of the vulnerability provided by the CVE system, including the manifestation, the potential impact, and the environment where the vulnerability may occur.<br>• CWE ID: The Common Weakness Enumeration identifier that categorizes the type of the vulnerability exploits.<br>• Vulnerable Code: The source code snippet containing the vulnerability, which will be modified in the commit.<br>• Patched Code: The source code snippet that has been committed to fix the vulnerability in the vulnerable code.<br>• Patch Diff: A detailed line-level difference between the vulnerable and patched code, consisting of added and deleted lines.</li></ul>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RAG </tag>
            
            <tag> 漏洞检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLM应用（一）：使用Haytack搭建RAG</title>
      <link href="/2025/03/04/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/"/>
      <url>/2025/03/04/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>思考：是否需要将文档分为检索部分和知识部分？</p><p>Haystack：一个用于构建基于LLM的应用程序的框架，包括：</p><ul><li>Document：Haystack的核心数据类型</li><li>component：组件单元，用于实现一个功能，例如：清理文件、切分文档、生成嵌入、初步检索、重排序等等</li><li>pipeline：流水线，将组件串联起来，自动依次调用组件</li><li>document store：存储文档的向量数据库</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install haystack-ai </span><br></pre></td></tr></table></figure><h2 id="Document">Document</h2><p>向量数据库的基本存储单元</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Document</span>(metaclass=_BackwardCompatible):</span><br><span class="line"><span class="comment"># 文档的ID</span></span><br><span class="line"><span class="built_in">id</span>: <span class="built_in">str</span> = field(default=<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文档的内容</span></span><br><span class="line">content: <span class="type">Optional</span>[<span class="built_in">str</span>] = field(default=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检索和重排序时文档的分数</span></span><br><span class="line">score: <span class="type">Optional</span>[<span class="built_in">float</span>] = field(default=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 文档的embedding，一个向量</span></span><br><span class="line">embedding: <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">float</span>]] = field(default=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文档的稀疏embedding，一个index-value的稀疏向量</span></span><br><span class="line">sparse_embedding: <span class="type">Optional</span>[SparseEmbedding] = field(default=<span class="literal">None</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 文档存在表格时，其pandas dataframe</span></span><br><span class="line">dataframe: <span class="type">Optional</span>[DataFrame] = field(default=<span class="literal">None</span>) </span><br><span class="line"><span class="comment"># 文档的二进制数据</span></span><br><span class="line">blob: <span class="type">Optional</span>[ByteStream] = field(default=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 文档的元数据，例如文档名，文档作者，文档时间等</span></span><br><span class="line">meta: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = field(default_factory=<span class="built_in">dict</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SparseEmbedding</span>:</span><br><span class="line">indices: <span class="type">List</span>[<span class="built_in">int</span>]</span><br><span class="line">values: <span class="type">List</span>[<span class="built_in">float</span>]</span><br></pre></td></tr></table></figure><h2 id="Component">Component</h2><p>需要标明该组件单元的输入、输出和处理代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Document, component</span><br><span class="line"><span class="meta">@component</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DocumentCleaner</span>:</span><br><span class="line">        <span class="comment"># 输出在注解处标明</span></span><br><span class="line"><span class="meta">@component.output_types(<span class="params">documents=<span class="type">List</span>[Document]</span>) </span></span><br><span class="line">        <span class="comment"># 输入在方法参数处标明</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, documents: <span class="type">List</span>[Document]</span>): </span><br><span class="line"><span class="comment"># 处理代码在run()方法里</span></span><br><span class="line">cleaned_docs = clean(documents) <span class="comment"># 清理文档内容...</span></span><br><span class="line">                <span class="comment"># 返回值必须是一个字典，key是和输出注解同名</span></span><br><span class="line">                <span class="comment"># 的字符串，value是清理好的文档列表</span></span><br><span class="line"><span class="keyword">return</span> &#123;<span class="string">&quot;documents&quot;</span>: cleaned_docs&#125; </span><br></pre></td></tr></table></figure><h2 id="Pipeline">Pipeline</h2><ul><li>将定义好的组件单元(component)添加到流水线中</li><li>将组件单元连接起来，一般情况下都是有向无环图</li><li>组件单元的输入即可以来自内部的前一个组件的输出，也可以来自外部传入的数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Pipeline</span>:</span><br><span class="line"><span class="comment"># 启动流水线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params"></span></span><br><span class="line"><span class="params">self, </span></span><br><span class="line"><span class="params">        <span class="comment"># 外部传入的数据，通过字典指定要给哪个组件传入哪个输入</span></span></span><br><span class="line"><span class="params">data: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], </span></span><br><span class="line"><span class="params">        <span class="comment"># 流水线的最终输出，通过字典说明哪个组件的哪个输出</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]: </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 将组件instance加入流水线，并命名为name</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_component</span>(<span class="params">self, name: <span class="built_in">str</span>, instance: Component</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将两个组件的输入和输出连接起来</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connect</span>(<span class="params">self, sender: <span class="built_in">str</span>, receiver: <span class="built_in">str</span></span>)</span><br></pre></td></tr></table></figure><h2 id="Converter">Converter</h2><p>haystack有一些可以将其他格式的文件转换成Document的组件，比如文本文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack.components.converters <span class="keyword">import</span> TextFileToDocument</span><br><span class="line"></span><br><span class="line">converter = TextFileToDocument()</span><br><span class="line">docs = converter.run(sources=[<span class="string">&quot;./files/hello_world.txt&quot;</span>])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;id: <span class="subst">&#123;docs[<span class="number">0</span>].<span class="built_in">id</span>&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;docs[<span class="number">0</span>].content&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;docs[<span class="number">0</span>].score&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;embedding: <span class="subst">&#123;docs[<span class="number">0</span>].embedding&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sparse_embedding: <span class="subst">&#123;docs[<span class="number">0</span>].sparse_embedding&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;meta: <span class="subst">&#123;docs[<span class="number">0</span>].meta&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>TextFileToDocument：一个component组件，输入是知识库文件路径列表list[Path]，输出是一个文档列表list[Document]</li><li>输出结果：（没有embedding处理流程和检索流程，所以没有embedding和score）</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">id: 85a2d0b785a183d80b84c23f2325d6e0dcda73da7304f0dc217ac55f2eb1a0b8</span><br><span class="line">content: Hello World!</span><br><span class="line">score: None</span><br><span class="line">embedding: None</span><br><span class="line">sparse_embedding: None</span><br><span class="line">meta: &#123;&#x27;file_path&#x27;: &#x27;hello_world.txt&#x27;&#125;</span><br></pre></td></tr></table></figure><h2 id="Spliter">Spliter</h2><p>文档切分是RAG的第一个核心点，目前主流有两种方式：直接切分和语法切分</p><p>在介绍具体切分方法之前，需要回答：什么样的文档块是好的？</p><ul><li><p>文档块长度需要适中，这个长度不好拿捏</p><ul><li>长文档块的缺点：</li></ul><ol><li>输入上下文增大，降低回答质量</li><li>信息量过多，检索准确度降低</li><li>信息量过多，正确的参考信息被太多无关信息淹没，大模型找不到对应的内容(影响attention计算的精确度)</li></ol><ul><li>短文档块的缺点：</li></ul><ol><li>信息量过少，大模型找不到参考信息</li><li>文档数量提升，降低检索速度</li><li>更多的语义碎片，丢失语义连贯性和长文本中的实体依赖关系，俗称“说话说一半”</li></ol><ul><li>文档块的内容要全面：但往往全面的文档块会很长，所以更重要的是如何在保证文档块长度适中的情况下，把“说话说一半”提升到“说话说四分之三”*</li><li>文档块的长度要平均：尽量保证所有文档块的长度都差不多长。因为在计算相似度分数时，嵌入模型会更倾向于给短文档块打更高的分数</li></ul></li></ul><h3 id="DocumentSplitter">DocumentSplitter</h3><ul><li>split_by：常用的基本单位有page、passage、sentence、line、word，这里我们以词(word)为基本单位进行切分。哪个基本单位好呢？<ul><li>word看起来很好，因为它可以保证所有的文档块都一样长，足够平均；但在头尾处会出现严重的不连贯现象</li><li>page和passage则是的文档块长度分布不均，以及超长文档块的出现</li><li>所以一般而言sentence或line是个不错的选择</li></ul></li><li>split_length：切分的基本长度</li><li>split_overlap：为了减少“说话说一半”的情况出现，让文档块之间相互重叠。假如2 3是连贯内容，重叠就可以使得它们连起来；不重叠则会被切断<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/overlap.png" alt="图片错误"></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">numbers = <span class="string">&quot;0 1 2 3 4 5 6 7 8 9&quot;</span></span><br><span class="line">document = Document(content=numbers)</span><br><span class="line">splitter = DocumentSplitter(split_by=<span class="string">&quot;word&quot;</span>, split_length=<span class="number">3</span>, split_overlap=<span class="number">1</span>)</span><br><span class="line">docs = splitter.run(documents=[document])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;document: <span class="subst">&#123;document.content&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> index,doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;document_<span class="subst">&#123;index&#125;</span>: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">document: 0 1 2 3 4 5 6 7 8 9</span><br><span class="line">document_0: 0 1 2 </span><br><span class="line">document_1: 2 3 4 </span><br><span class="line">document_2: 4 5 6 </span><br><span class="line">document_3: 6 7 8 </span><br><span class="line">document_4: 8 9</span><br></pre></td></tr></table></figure><h3 id="NLTKDocumentSplitter">NLTKDocumentSplitter</h3><p>奇怪的输入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack.components.preprocessors <span class="keyword">import</span> NLTKDocumentSplitter, DocumentSplitter</span><br><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;The dog was called Wellington. It belonged to Mrs. Shears who was our friend. </span></span><br><span class="line"><span class="string">She lived on the opposite side of the road, two houses to the left.&quot;&quot;&quot;</span></span><br><span class="line">document = Document(content=text)</span><br></pre></td></tr></table></figure><p>简单以句子为单位切分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">simple_splitter = DocumentSplitter(split_by=<span class="string">&quot;sentence&quot;</span>, split_length=<span class="number">1</span>, split_overlap=<span class="number">0</span>)</span><br><span class="line">simple_docs = simple_splitter.run(documents=[document])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nsimple:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> index, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(simple_docs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;document_<span class="subst">&#123;index&#125;</span>: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">simple:</span><br><span class="line">document_0: The dog was called Wellington.</span><br><span class="line">document_1:  It belonged to Mrs.</span><br><span class="line">document_2:  Shears who was our friend.</span><br><span class="line">document_3:  She lived on the opposite side of the road, two houses to the left.</span><br></pre></td></tr></table></figure><p>无法区分 Mrs. Shears的点号和句号，所以我们需要nltk来对单词和符号进行tag标注</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nltk_splitter = NLTKDocumentSplitter(split_by=<span class="string">&quot;sentence&quot;</span>, split_length=<span class="number">1</span>, split_overlap=<span class="number">0</span>)</span><br><span class="line">nltk_docs = nltk_splitter.run(documents=[document])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nnltk:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> index, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(nltk_docs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;document_<span class="subst">&#123;index&#125;</span>: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nltk:</span><br><span class="line">document_0: The dog was called Wellington. </span><br><span class="line">document_1: It belonged to Mrs. Shears who was our friend. </span><br><span class="line">document_2: She lived on the opposite side of the road, two houses to the left.</span><br></pre></td></tr></table></figure><h2 id="Retreiver">Retreiver</h2><h3 id="BM25Retriever原理">BM25Retriever原理</h3><p>BM25是搜索引擎领域计算查询与文档相关性的排名函数，它是一种基于词袋的检索函数：通过统计查询和文档的单词匹配数量来计算二者相似度分数<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/bm25.png" alt="图片错误"><br>其中：</p><ul><li>查询<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>包含关键字<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>q</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">q_1,...,q_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(q_i,D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span>是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在文档<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>中的词频</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|D|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span></span>是文档长度</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>v</mi><mi>g</mi><mi>d</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">avgdl</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">vg</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>是平均文档长度;<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>D</mi><mi>F</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">IDF(q_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的逆向文档频率权重;<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">k_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>是超参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">document_store = InMemoryDocumentStore()</span><br><span class="line">documents = [</span><br><span class="line">Document(content=<span class="string">&quot;There are over 7,000 languages spoken around the world today.&quot;</span>),</span><br><span class="line">Document(content=<span class="string">&quot;Elephants have been observed to behave in a way that indicates a high level of self-awareness, such as recognizing themselves in mirrors.&quot;</span>),</span><br><span class="line">Document(content=<span class="string">&quot;In certain parts of the world, like the Maldives, Puerto Rico, and San Diego, you can witness the phenomenon of bioluminescent waves.&quot;</span>)</span><br><span class="line">]</span><br><span class="line">document_store.write_documents(documents=documents)</span><br><span class="line">retriever = InMemoryBM25Retriever(document_store=document_store)</span><br><span class="line">docs = retriever.run(query=<span class="string">&quot;How many languages are spoken around the world today?&quot;</span>)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">content: There are over 7,000 languages spoken around the world today.</span><br><span class="line">score: 7.815769833242408</span><br><span class="line">content: In certain parts of the world, like the Maldives, Puerto Rico, and San Diego, you can witness the phenomenon of bioluminescent waves.</span><br><span class="line">score: 4.314753296196667</span><br><span class="line">content: Elephants have been observed to behave in a way that indicates a high level of self-awareness, such as recognizing themselves in mirrors.</span><br><span class="line">score: 3.652595952218814</span><br></pre></td></tr></table></figure><ul><li>优缺点<ul><li>速度快：基于统计的分数计算公式很简单，可以快速处理大规模文本数据</li><li>存储开销小：除文本外无需存储额外数据。如果下游大模型通过API调用，rag不需要显卡也能跑起来，而且很快</li><li>太依赖关键字：query质量不高就搜不到，无法捕获文本的上下文语义信息。比如，在搜索引擎中，如果不输入关键字那必然搜不到我们想要的内容</li></ul></li></ul><h3 id="Bert">Bert</h3><p>最近几年，一种基于BERT架构衍生出来的多种语义检索技术被更多地用到了RAG中，他是一种encoder-only的transformer架构：</p><ul><li>Tokenizer：words -&gt; tokens</li><li>Embedding：tokens -&gt; vectors</li><li>Encoder Stack：vectors -&gt; vectors</li></ul><p>简言之，它可以将文本转换成若干token vector<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/BERT.png" alt="图片错误"></p><h3 id="DenseEmbeddingRetriever-文本嵌入模型">DenseEmbeddingRetriever: 文本嵌入模型</h3><p>密集嵌入检索器基于双编码器(Bi-Encoder)架构，在BERT上面外加一层池化层(Pooling)，得到单一的句向量，存储到document.embedding中。</p><ul><li>sentence -&gt;BERT-Encoder -&gt; token vectors</li><li>token vectors -&gt; Pooling Layer -&gt; sentence vector</li><li>score(SentenceA, SentenceB) = cosine_similarity(vectorA,vectorB)<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/bi-encoder.png" alt="图片错误"></li></ul><h3 id="DenseEmbeddingRetriever-相似度计算">DenseEmbeddingRetriever: 相似度计算</h3><p>密集向量会交给一个经过训练的嵌入模型生成，它可以将相似的句子映射到高维空间中距离相近、方向相似的向量，常用的相似度分数计算公式有两种：</p><ul><li>余弦相似度：常用的相似度计算公式，计算两个向量之间的夹角的余弦值。两个向量的方向越一致相似度越高</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>S</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>l</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>A</mi><mo separator="true">⋅</mo><mi>B</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mtext> </mtext><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>B</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>A</mi><mi>i</mi></msub><msub><mi>B</mi><mi>i</mi></msub></mrow><mrow><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>A</mi><mi>i</mi></msub><msub><mi>A</mi><mi>i</mi></msub></mrow></msqrt><mo separator="true">⋅</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>B</mi><mi>i</mi></msub><msub><mi>B</mi><mi>i</mi></msub></mrow></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">CosineSimilarity=\frac{A·B}{||A||\space||B||}=\frac{\sum_{i=1}^nA_iB_i}{\sqrt{\sum_{i=1}^nA_iA_i}·\sqrt{\sum_{i=1}^nB_iB_i}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">os</span><span class="mord mathnormal">in</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">imi</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2963em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣∣</span><span class="mord mathnormal">A</span><span class="mord">∣∣</span><span class="mspace"> </span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">∣∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.624em;vertical-align:-1.13em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.494em;"><span style="top:-2.1727em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9373em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8973em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067l0 -0c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3027em;"><span></span></span></span></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9373em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8973em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067l0 -0c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3027em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6897em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>欧式似度：直接计算两个向量之间的欧几里得距离，然后取个倒数得到相似度分数。也可以用其他距离：曼哈顿距离、汉明距离等</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>u</mi><mi>c</mi><mi>l</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>a</mi><mi>n</mi><mi>S</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>l</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo>−</mo><msub><mi>B</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">EuclideanSimilarity=\frac{1}{1+\sqrt{\sum_{i=1}^n(A_i-B_i)^2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">an</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">imi</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4514em;vertical-align:-1.13em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.1727em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9373em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.8973em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067l0 -0c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3027em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h4 id="例子">例子</h4><ul><li>模型: sentence-transformers/all-MiniLM-L6-v2, 22.7M params</li><li>相似度分数：余弦相似度</li></ul><h5 id="处理查询">处理查询</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">document_store = InMemoryDocumentStore(embedding_similarity_function=<span class="string">&quot;cosine&quot;</span>)</span><br><span class="line">document_embedder = SentenceTransformersDocumentEmbedder(</span><br><span class="line">model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span></span><br><span class="line">)</span><br><span class="line">document_embedder.warm_up()</span><br><span class="line">documents_with_embeddings = document_embedder.run(documents)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line">document_store.write_documents(documents_with_embeddings)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> documents_with_embeddings:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;embedding: <span class="subst">&#123;doc.embedding&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">query_pipeline = Pipeline()</span><br><span class="line">query_pipeline.add_component(</span><br><span class="line"><span class="string">&quot;text_embedder&quot;</span>,</span><br><span class="line">SentenceTransformersTextEmbedder(model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>),</span><br><span class="line">)</span><br><span class="line">query_pipeline.add_component(</span><br><span class="line"><span class="string">&quot;retriever&quot;</span>, InMemoryEmbeddingRetriever(document_store=document_store)</span><br><span class="line">)</span><br><span class="line">query_pipeline.connect(<span class="string">&quot;text_embedder.embedding&quot;</span>, <span class="string">&quot;retriever.query_embedding&quot;</span>)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;How many languages are there?&quot;</span></span><br><span class="line">result = query_pipeline.run(&#123;<span class="string">&quot;text_embedder&quot;</span>: &#123;<span class="string">&quot;text&quot;</span>: query&#125;&#125;)</span><br><span class="line">result_documents = result[<span class="string">&quot;retriever&quot;</span>][<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> result_documents:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">content: There are over 7,000 languages spoken around the world today.</span><br><span class="line">score: 0.7557791972968138</span><br><span class="line"></span><br><span class="line">content: Elephants have been observed to behave in a way that indicates a high level of self-awareness, such as recognizing themselves in mirrors.</span><br><span class="line">score: 0.04221229186262071</span><br><span class="line"></span><br><span class="line">content: In certain parts of the world, like the Maldives, Puerto Rico, and San Diego, you can witness the phenomenon of bioluminescent waves.</span><br><span class="line">score: -0.001667825878752048</span><br></pre></td></tr></table></figure><h4 id="优缺点">优缺点</h4><ul><li>速度快：可以提前在GPU上计算并存储文档块的dense embedding，计算相似度就会很快</li><li>存储开销小：每个文档块只需要额外存储一个高维向量(通常768或1024维)</li><li>捕获句子的语义信息：只要是相似的句子，关键字不匹配也可以检索到</li><li>丢失词元信息：BERT产生的众多词元向量全部被映射到单一句向量，丢失了很多文本中的细节。快速地粗读文本，速度虽快但忽略了细节，只了解了个大概</li></ul><h3 id="SimilarityReranker-相似度计算模型">SimilarityReranker: 相似度计算模型</h3><ul><li><p>similarity reranker基于交叉编码器(cross-encoder)架构</p></li><li><p>直接将两个句子串联起来，交给BERT，使得两个句子的词元向量可以在BERT内部相互交叉(cross)地进行交互，最终经过softmax得到一个相似度分数<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/reranker.png" alt="图片错误"></p></li><li><p>cross vs. colbert: 词元向量的交互从相似度计算阶段(colbert)，提前到BERT模型内部(cross)<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/cross-vs-colbert.png" alt="图片错误"></p></li></ul><h4 id="例子-2">例子</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> haystack.components.rankers <span class="keyword">import</span> TransformersSimilarityRanker</span><br><span class="line"></span><br><span class="line">documents = [</span><br><span class="line">    Document(content=<span class="string">&quot;There are over 7,000 languages spoken around the world today.&quot;</span>),</span><br><span class="line">    Document(content=<span class="string">&quot;Elephants have been observed to behave in a way that indicates </span></span><br><span class="line"><span class="string">    a high level of self-awareness, such as recognizing themselves in mirrors.&quot;</span>),</span><br><span class="line">    Document(content=<span class="string">&quot;In certain parts of the world, like the Maldives, Puerto Rico, </span></span><br><span class="line"><span class="string">    and San Diego, you can witness the phenomenon of bioluminescent waves.&quot;</span>),</span><br><span class="line">]</span><br><span class="line">ranker = TransformersSimilarityRanker(model=<span class="string">&quot;cross-encoder/ms-marco-MiniLM-L-6-v2&quot;</span>)</span><br><span class="line">ranker.warm_up()</span><br><span class="line">query = <span class="string">&quot;How many languages are there?&quot;</span></span><br><span class="line">ranked_documents = ranker.run(query=query, documents=documents)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> ranked_documents:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-2">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">content: There are over 7,000 languages spoken around the world today.</span><br><span class="line">score: 0.9998884201049805</span><br><span class="line"></span><br><span class="line">content: Elephants have been observed to behave in a way that indicates </span><br><span class="line">a high level of self-awareness, such as recognizing themselves in mirrors.</span><br><span class="line">score: 1.4616251974075567e-05</span><br><span class="line"></span><br><span class="line">content: In certain parts of the world, like the Maldives, Puerto Rico, </span><br><span class="line">and San Diego, you can witness the phenomenon of bioluminescent waves.</span><br><span class="line">score: 1.4220857337932102e-05</span><br></pre></td></tr></table></figure><h3 id="优缺点-2">优缺点</h3><ul><li>充分利用词元信息：相似度直接在模型内部完成计算。同时看两个文本，交叉理解两个文本的单词的含义，训练好的模型可以得到很好的相似度计算结果</li><li>在线计算：所有的计算都要在GPU上在线完成，无法提前存储一些信息，实现之前的离线计算，因此会很慢</li></ul><h2 id="Simple-RAG">Simple RAG</h2><p>挑一种文档划分方法，再挑一个检索器，一个简单的RAG就可以完成了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> prompt_toolkit <span class="keyword">import</span> prompt</span><br><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> haystack.utils <span class="keyword">import</span> Secret</span><br><span class="line"><span class="keyword">from</span> haystack.document_stores.in_memory <span class="keyword">import</span> InMemoryDocumentStore</span><br><span class="line"><span class="keyword">from</span> haystack.components.fetchers <span class="keyword">import</span> LinkContentFetcher</span><br><span class="line"><span class="keyword">from</span> haystack.components.converters <span class="keyword">import</span> HTMLToDocument</span><br><span class="line"><span class="keyword">from</span> haystack.components.preprocessors <span class="keyword">import</span> DocumentSplitter</span><br><span class="line"><span class="keyword">from</span> haystack.components.writers <span class="keyword">import</span> DocumentWriter</span><br><span class="line"><span class="keyword">from</span> haystack.components.retrievers.in_memory <span class="keyword">import</span> InMemoryEmbeddingRetriever</span><br><span class="line"><span class="keyword">from</span> haystack.components.generators <span class="keyword">import</span> OpenAIGenerator</span><br><span class="line"><span class="keyword">from</span> haystack.components.builders.prompt_builder <span class="keyword">import</span> PromptBuilder</span><br><span class="line"><span class="keyword">from</span> haystack.components.embedders <span class="keyword">import</span> (</span><br><span class="line">    SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder,)</span><br></pre></td></tr></table></figure><h3 id="处理文档">处理文档</h3><ul><li>使用sentence-transformers/all-MiniLM-L6-v2嵌入模型进行检索</li><li>以3行为单位进行切分，并且有1行的overlap</li><li>将南京大学的wiki网页作为知识库：<a href="https://en.wikipedia.org/wiki/Nanjing_University">https://en.wikipedia.org/wiki/Nanjing_University</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">document_store = InMemoryDocumentStore()</span><br><span class="line">fetcher = LinkContentFetcher()</span><br><span class="line">converter = HTMLToDocument()</span><br><span class="line">splitter = DocumentSplitter(split_by=<span class="string">&quot;sentence&quot;</span>, split_length=<span class="number">3</span>, split_overlap=<span class="number">1</span>)</span><br><span class="line">document_embedder = SentenceTransformersDocumentEmbedder(</span><br><span class="line">    model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span></span><br><span class="line">)</span><br><span class="line">writer = DocumentWriter(document_store = document_store)</span><br><span class="line"></span><br><span class="line">indexing_pipeline = Pipeline()</span><br><span class="line">indexing_pipeline.add_component(<span class="string">&quot;fetcher&quot;</span>, fetcher)</span><br><span class="line">indexing_pipeline.add_component(<span class="string">&quot;converter&quot;</span>, converter)</span><br><span class="line">indexing_pipeline.add_component(<span class="string">&quot;splitter&quot;</span>, splitter)</span><br><span class="line">indexing_pipeline.add_component(<span class="string">&quot;document_embedder&quot;</span>, document_embedder)</span><br><span class="line">indexing_pipeline.add_component(<span class="string">&quot;writer&quot;</span>, writer)</span><br><span class="line"></span><br><span class="line">indexing_pipeline.connect(<span class="string">&quot;fetcher.streams&quot;</span>, <span class="string">&quot;converter.sources&quot;</span>)</span><br><span class="line">indexing_pipeline.connect(<span class="string">&quot;converter.documents&quot;</span>, <span class="string">&quot;splitter.documents&quot;</span>)</span><br><span class="line">indexing_pipeline.connect(<span class="string">&quot;splitter.documents&quot;</span>, <span class="string">&quot;document_embedder.documents&quot;</span>)</span><br><span class="line">indexing_pipeline.connect(<span class="string">&quot;document_embedder.documents&quot;</span>, <span class="string">&quot;writer.documents&quot;</span>)</span><br><span class="line"></span><br><span class="line">indexing_pipeline.run(data=&#123;<span class="string">&quot;fetcher&quot;</span>: &#123;<span class="string">&quot;urls&quot;</span>: [<span class="string">&quot;https://en.wikipedia.org/wiki/Nanjing_University&quot;</span>]&#125;&#125;)</span><br></pre></td></tr></table></figure><h3 id="处理查询-2">处理查询</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Given these documents, answer the question.</span></span><br><span class="line"><span class="string">Documents:</span></span><br><span class="line"><span class="string">&#123;% for doc in documents %&#125;</span></span><br><span class="line"><span class="string">    &#123;&#123; doc.content &#125;&#125;</span></span><br><span class="line"><span class="string">&#123;% endfor %&#125;</span></span><br><span class="line"><span class="string">Question: &#123;&#123;question&#125;&#125;</span></span><br><span class="line"><span class="string">Answer:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">api_key = <span class="string">&quot;xxx&quot;</span></span><br><span class="line">model = <span class="string">&quot;gpt-4o-mini&quot;</span></span><br><span class="line">api_base_url = <span class="literal">None</span></span><br><span class="line">query_embedder = SentenceTransformersTextEmbedder(model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>)</span><br><span class="line">retriever = InMemoryEmbeddingRetriever(document_store=document_store)</span><br><span class="line">prompt_builder = PromptBuilder(template=prompt_template)</span><br><span class="line">llm = OpenAIGenerator(</span><br><span class="line">    api_key=Secret.from_token(api_key),</span><br><span class="line">    model=model,</span><br><span class="line">    api_base_url=api_base_url</span><br><span class="line">)</span><br><span class="line">rag_pipeline = Pipeline()</span><br><span class="line">rag_pipeline.add_component(<span class="string">&quot;query_embedder&quot;</span>, query_embedder)</span><br><span class="line">rag_pipeline.add_component(<span class="string">&quot;retriever&quot;</span>, retriever)</span><br><span class="line">rag_pipeline.add_component(<span class="string">&quot;prompt_builder&quot;</span>, prompt_builder)</span><br><span class="line">rag_pipeline.add_component(<span class="string">&quot;llm&quot;</span>, llm)</span><br><span class="line">rag_pipeline.connect(<span class="string">&quot;query_embedder.embedding&quot;</span>, <span class="string">&quot;retriever.query_embedding&quot;</span>)</span><br><span class="line">rag_pipeline.connect(<span class="string">&quot;retriever.documents&quot;</span>, <span class="string">&quot;prompt_builder.documents&quot;</span>)</span><br><span class="line">rag_pipeline.connect(<span class="string">&quot;prompt_builder.prompt&quot;</span>, <span class="string">&quot;llm.prompt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    question = prompt(<span class="string">&quot;&gt; &quot;</span>)</span><br><span class="line">    results = rag_pipeline.run(</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;query_embedder&quot;</span>: &#123;<span class="string">&quot;text&quot;</span>: question&#125;,</span><br><span class="line">            <span class="string">&quot;prompt_builder&quot;</span>: &#123;<span class="string">&quot;question&quot;</span>: question&#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    reply = results[<span class="string">&quot;llm&quot;</span>][<span class="string">&quot;replies&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(reply)</span><br></pre></td></tr></table></figure><h3 id="测试">测试</h3><h4 id="What-is-the-motto-of-Nanjing-University？">What is the motto of Nanjing University？</h4><p>The motto of Nanjing University is “诚朴雄伟励学敦行,” which translates to “Sincerity with Aspiration, Perseverance and Integrity” in English. The first half of this motto was the motto during the National Central University time, and the last half was quoted from the classic literature work Book of Rites.<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/motto.png" alt="图片错误"></p><h4 id="What-is-the-song-of-Nanjing-University？">What is the song of Nanjing University？</h4><p>The song of Nanjing University is the university song, which was created in 1916. It is the first school song in the modern history of Nanjing University. The lyrics were written by Jiang Qian, and the melody was composed by Li Shutong. The song was recovered in 2002.<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/song.png" alt="图片错误"></p><h4 id="问一些大模型不知道的问题">问一些大模型不知道的问题</h4><p>question: Who is the modern China’s first PhD in Chinese Language and Literature?</p><h5 id="Chatgpt-answer">Chatgpt answer</h5><p>一会说1986年的郭齐勇，一会说1983年的陈平原<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/gpt.png" alt="图片错误"></p><h5 id="RAG-answer">RAG answer</h5><p>The modern China’s first PhD in Chinese Language and Literature is Mo Lifeng (莫砺锋), as mentioned in the documents.<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/phd.png" alt="图片错误"></p><h2 id="Advanced-RAG-检索结果合并">Advanced RAG: 检索结果合并</h2><p>不同的检索器有不同的侧重点，会得到不同的相似度分数分布，如何综合考虑？例如一本书我既想略读整体(dense embedding)，也想跳着读重点部分(sparse embedding)</p><h3 id="权重合并-Weight-Merge">权重合并(Weight Merge)</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>α</mi><mo separator="true">⋅</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo separator="true">⋅</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha·scale(s_1)+(1-\alpha)·scale(s_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">sc</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">sc</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><ul><li>两种检索机制的分数的值域、分布不一致，通过放缩补偿</li><li>通过加权和计算综合分数</li></ul><h3 id="RRF-倒排融合">RRF(倒排融合)</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>R</mi><mi>F</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mo>∈</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mi>r</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">RRFscore(d\in D)=\sum_{r\in R}\frac{1}{k+r(d)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">RRF</span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.6431em;vertical-align:-1.3217em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>只考虑文档在排序中的位置，忽略分数分布</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>是文档d在一种检索机制下的排序</li><li>k是超参</li></ul><h4 id="例子-3">例子</h4><h5 id="import">import</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Document, Pipeline</span><br><span class="line"><span class="keyword">from</span> haystack.document_stores.in_memory <span class="keyword">import</span> InMemoryDocumentStore</span><br><span class="line"><span class="keyword">from</span> haystack.components.embedders <span class="keyword">import</span> (</span><br><span class="line">    SentenceTransformersTextEmbedder,</span><br><span class="line">    SentenceTransformersDocumentEmbedder,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> haystack.components.retrievers.in_memory <span class="keyword">import</span> InMemoryBM25Retriever</span><br><span class="line"><span class="keyword">from</span> haystack.components.retrievers <span class="keyword">import</span> InMemoryEmbeddingRetriever</span><br><span class="line"><span class="keyword">from</span> haystack.components.joiners.document_joiner <span class="keyword">import</span> DocumentJoiner</span><br></pre></td></tr></table></figure><h5 id="文档处理">文档处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">document_store = InMemoryDocumentStore(embedding_similarity_function=<span class="string">&quot;cosine&quot;</span>)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;What are effective strategies to improve English speaking skills?&quot;</span></span><br><span class="line">documents = [</span><br><span class="line">    Document(content=<span class="string">&quot;Practicing with native speakers enhances English </span></span><br><span class="line"><span class="string">                      speaking proficiency.&quot;</span>),</span><br><span class="line">    Document(content=<span class="string">&quot;Regular participation in debates and discussions </span></span><br><span class="line"><span class="string">                      refine public speaking skills in English.&quot;</span>),</span><br><span class="line">    Document(content=<span class="string">&quot;Studying the history of the English language does</span></span><br><span class="line"><span class="string">                      not directly improve speaking skills.&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">document_embedder = SentenceTransformersDocumentEmbedder(</span><br><span class="line">    model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span></span><br><span class="line">)</span><br><span class="line">document_embedder.warm_up()</span><br><span class="line">documents_with_embeddings = document_embedder.run(documents)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line">document_store.write_documents(documents_with_embeddings)</span><br></pre></td></tr></table></figure><h5 id="bm25检索">bm25检索</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bm25_retriever = InMemoryBM25Retriever(document_store=document_store，scale_score=<span class="literal">True</span>)</span><br><span class="line">bm25_docs = bm25_retriever.run(query=query)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;bm25:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> bm25_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-3">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">content: Studying the history of the English language does not directly improve </span><br><span class="line">speaking skills.</span><br><span class="line">score: 0.5593245377361279</span><br><span class="line">content: Regular participation in debates and discussions refine public speaking </span><br><span class="line">skills in English.</span><br><span class="line">score: 0.545159185512614</span><br><span class="line">content: Practicing with native speakers enhances English speaking proficiency.</span><br><span class="line">score: 0.5387709786621966</span><br></pre></td></tr></table></figure><h5 id="dense-embedding检索">dense embedding检索</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">query_pipeline = Pipeline()</span><br><span class="line">query_pipeline.add_component(</span><br><span class="line">    <span class="string">&quot;text_embedder&quot;</span>,</span><br><span class="line">    SentenceTransformersTextEmbedder(model=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>),</span><br><span class="line">)</span><br><span class="line">query_pipeline.add_component(</span><br><span class="line">    <span class="string">&quot;dense_retriever&quot;</span>, InMemoryEmbeddingRetriever(document_store=document_store，scale_score=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">query_pipeline.connect(<span class="string">&quot;text_embedder.embedding&quot;</span>, <span class="string">&quot;dense_retriever.query_embedding&quot;</span>)</span><br><span class="line">dense_docs = query_pipeline.run(&#123;<span class="string">&quot;text_embedder&quot;</span>: &#123;<span class="string">&quot;text&quot;</span>: query&#125;&#125;)[<span class="string">&quot;dense_retriever&quot;</span>][<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dense:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> dense_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-4">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">content: Practicing with native speakers enhances English speaking proficiency.</span><br><span class="line">score: 0.8296398226909952</span><br><span class="line"></span><br><span class="line">content: Regular participation in debates and discussions refine public speaking </span><br><span class="line">skills in English.</span><br><span class="line">score: 0.8017774366152697</span><br><span class="line"></span><br><span class="line">content: Studying the history of the English language does not directly improve </span><br><span class="line">speaking skills.</span><br><span class="line">score: 0.7334273104138469</span><br></pre></td></tr></table></figure><h5 id="权重合并">权重合并</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">joiner = DocumentJoiner(join_mode=<span class="string">&quot;merge&quot;</span>, weights=[<span class="number">0.3</span>, <span class="number">0.7</span>])</span><br><span class="line">merge_docs = joiner.run(documents=[bm25_docs, dense_docs])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> merge_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-5">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">content: Practicing with native speakers enhances English speaking proficiency.</span><br><span class="line">score: 0.7423791694823556</span><br><span class="line">content: Regular participation in debates and discussions refine public speaking </span><br><span class="line">skills in English.</span><br><span class="line">score: 0.724791961284473</span><br><span class="line">content: Studying the history of the English language does not directly improve </span><br><span class="line">speaking skills.</span><br><span class="line">score: 0.6811964786105311</span><br></pre></td></tr></table></figure><h5 id="RRF合并">RRF合并</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">joiner = DocumentJoiner(join_mode=<span class="string">&quot;reciprocal_rank_fusion&quot;</span>)</span><br><span class="line">rrf_docs = joiner.run(documents=[bm25_docs,dense_docs])[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rrf:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> rrf_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-6">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">content: Studying the history of the English language does not directly improve speaking skills.</span><br><span class="line">score: 0.9841269841269842</span><br><span class="line">content: Practicing with native speakers enhances English </span><br><span class="line">speaking proficiency.</span><br><span class="line">score: 0.9841269841269842</span><br><span class="line">content: Regular participation in debates and discussions refine public speaking </span><br><span class="line">skills in English.</span><br><span class="line">score: 0.9838709677419354</span><br></pre></td></tr></table></figure><h5 id="RRF计算：haystack使用k-61，并且进行了额外的放缩处理，-R-是排序列表的数量">RRF计算：haystack使用k=61，并且进行了额外的放缩处理，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi>R</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|R|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord">∣</span></span></span></span>是排序列表的数量</h5><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>R</mi><mi>F</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mo>∈</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>k</mi><mrow><mi mathvariant="normal">∣</mi><mi>R</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo separator="true">⋅</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mi>r</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">RRFscore(d\in D)=\frac{k}{|R|}·\sum_{r\in R}\frac{1}{k+r(d)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">RRF</span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.6931em;vertical-align:-1.3217em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>Studying…：bm25的排序为1，dense的排序为3，因此：</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>61</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>0.984127</mn></mrow><annotation encoding="application/x-tex">61/2\times(1/(61+1)+1/(61+3))=0.984127</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">61/2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.984127</span></span></span></span></span></p><ul><li>Practicing…：bm25的排序为3，dense的排序为1，因此：</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>61</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>0.984127</mn></mrow><annotation encoding="application/x-tex">61/2\times(1/(61+3)+1/(61+1))=0.984127</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">61/2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.984127</span></span></span></span></span></p><ul><li>Regular…：bm25的排序为3，dense的排序为1，因此：</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>61</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>61</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>0.983871</mn></mrow><annotation encoding="application/x-tex">61/2\times(1/(61+2)+1/(61+2))=0.983871</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">61/2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/</span><span class="mopen">(</span><span class="mord">61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.983871</span></span></span></span></span></p><h3 id="重排序机制">重排序机制</h3><ul><li>有些检索器速度快但效果不好(dense,sparse,bm25)，有些检索器速度慢但效果好(colbert,cross)</li><li>可以先用速度快的检索器先网罗一批候选文档，再用效果好的检索器重新排序。先快速粗读所有文档，找出一批看起来不错的文档，再精读候选文档，找出质量好的</li></ul><h4 id="例子-4">例子</h4><h5 id="import-2">import</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> haystack <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> haystack.document_stores.in_memory <span class="keyword">import</span> InMemoryDocumentStore</span><br><span class="line"><span class="keyword">from</span> haystack.components.retrievers.in_memory <span class="keyword">import</span> InMemoryBM25Retriever</span><br><span class="line"><span class="keyword">from</span> haystack.components.rankers <span class="keyword">import</span> TransformersSimilarityRanker</span><br></pre></td></tr></table></figure><h5 id="文档处理-2">文档处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;What are effective strategies to improve English speaking skills?&quot;</span></span><br><span class="line">documents = [</span><br><span class="line">    Document(</span><br><span class="line">        content=<span class="string">&quot;Practicing with native speakers enhances English speaking proficiency.&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Document(</span><br><span class="line">        content=<span class="string">&quot;Daily vocabulary expansion is crucial for improving oral communication skills.&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Document(</span><br><span class="line">        content=<span class="string">&quot;Engaging in language exchange programs can significantly boost speaking abilities.&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Document(</span><br><span class="line">        content=<span class="string">&quot;Regular participation in debates and discussions refine public speaking skills in English.&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Document(</span><br><span class="line">        content=<span class="string">&quot;Studying the history of the English language does not directly improve speaking skills.&quot;</span></span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line">document_store = InMemoryDocumentStore()</span><br><span class="line">document_store.write_documents(documents)</span><br></pre></td></tr></table></figure><h5 id="bm25初步检索">bm25初步检索</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bm25_retriever = InMemoryBM25Retriever(document_store=document_store)</span><br><span class="line">bm25_docs = bm25_retriever.run(query=query, top_k=<span class="number">4</span>)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;bm25:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> bm25_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-7">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">bm25:</span><br><span class="line">content: Studying the history of the English language does not directly improve speaking skills.</span><br><span class="line">score: 3.1117211646172698</span><br><span class="line"></span><br><span class="line">content: Regular participation in debates and discussions refine public speaking skills in English.</span><br><span class="line">score: 2.443788686074245</span><br><span class="line"></span><br><span class="line">content: Practicing with native speakers enhances English speaking proficiency.</span><br><span class="line">score: 2.2622329312889553</span><br><span class="line"></span><br><span class="line">content: Daily vocabulary expansion is crucial for improving oral communication skills.</span><br><span class="line">score: 2.0359854825047066</span><br></pre></td></tr></table></figure><h5 id="重排序">重排序</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">reranker = TransformersSimilarityRanker(model=<span class="string">&quot;cross-encoder/ms-marco-MiniLM-L-6-v2&quot;</span>)</span><br><span class="line">reranker.warm_up()</span><br><span class="line">reranked_docs = reranker.run(query=query, documents=bm25_docs, top_k=<span class="number">3</span>)[<span class="string">&quot;documents&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;reranker:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> reranked_docs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;content: <span class="subst">&#123;doc.content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;doc.score&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure><h5 id="输出-8">输出</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">reranker:</span><br><span class="line">content: Practicing with native speakers enhances English speaking proficiency.</span><br><span class="line">score: 0.769904375076294</span><br><span class="line"></span><br><span class="line">content: Studying the history of the English language does not directly improve </span><br><span class="line">speaking skills.</span><br><span class="line">score: 0.5486361384391785</span><br><span class="line"></span><br><span class="line">content: Daily vocabulary expansion is crucial for improving oral communication </span><br><span class="line">skills.</span><br><span class="line">score: 0.3509156107902527</span><br></pre></td></tr></table></figure><h3 id="上下文丰富">上下文丰富</h3><p>小文档块的检索准确度更高，但丢失了更多上下文信息，因此可以在检索后丰富上下文来补偿</p><h4 id="上下文窗口扩展-Sentence-window-retrieval">上下文窗口扩展(Sentence window retrieval)</h4><ul><li>以小文档块为单位进行检索可以保证检索准确度，和相邻若干文档块合并形成大文档块可以保证信息量</li><li>翻阅书本时，突然扫到了重点，会下意识联系上下文看一看，看有没有额外的相关信息可以参考<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/sentence_window.png" alt="图片错误"></li></ul><h4 id="自动合并检索-Auto-merging-retrieval">自动合并检索(Auto-merging retrieval)</h4><ul><li>任何时候都进行上下文扩展并不合理，当检索命中的小文档块数量在大文档块中的占比达到一定阈值时(例如50%)，才进行合并</li><li>翻阅书本时，发现重点都聚集在某一章节，那这一章节可能都很重要<br><img src="pic/LLM%E5%BA%94%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BD%BF%E7%94%A8Haytack%E6%90%AD%E5%BB%BARAG/auto_merging.png" alt="图片错误"></li></ul>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RAG </tag>
            
            <tag> Haystack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HuggingFace使用笔记</title>
      <link href="/2025/02/17/HuggingFace%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/02/17/HuggingFace%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="模型下载">模型下载</h2><p>hugggingface.co无法访问。需要magic才能访问网站，但是仍然无法跑通代码。</p><p>解决方法：</p><p>terminal</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set HTTP_PROXY=http://127.0.0.1:7890</span><br><span class="line">set HTTPS_PROXY=https://127.0.0.1:7890</span><br><span class="line">pip install urllib3=1.25.11</span><br></pre></td></tr></table></figure><p>magic</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- DOMAIN-SUFFIX,cdn-lfs-us-1.huggingface.co, magic</span><br><span class="line">- DOMAIN-SUFFIX,huggingface.co, magic</span><br></pre></td></tr></table></figure><p>或者在代码中打开代理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;http_proxy&quot;</span>] = <span class="string">&quot;http://localhost:7890&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;https_proxy&quot;</span>] = <span class="string">&quot;http://localhost:7890&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议（三）：Kerberos</title>
      <link href="/2024/12/12/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AKerberos/"/>
      <url>/2024/12/12/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AKerberos/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>kerbaros是古希腊神话中的地狱三头犬，可以识别亡灵，防止活人进入地狱</p><h2 id="身份认证">身份认证</h2><h3 id="本地认证">本地认证</h3><p>登录自己的电脑<br>使用mimikatz抓取密码（SAM文件和lsass进程）</p><h3 id="网络认证">网络认证</h3><p>电脑之间的认证</p><h3 id="Kerberos协议">Kerberos协议</h3><p>客户端（client）：发送请求</p><p>服务端（Server）：接收方</p><p>密钥分发中心（Key Distribution Center，KDC）：</p><p>分为AS（Authentication Server）：认证服务器，专门认证客户端身份，发放客户用来访问TGS的TGT（票据授予票据）（安检）</p><p>TGS（Ticket Granting Ticket）：票据授予服务器，发放整个认证过程和客户端访问服务端时所需的服务授予票据（Ticket）（卖票）</p><p>第一步：客户端用身份信息去AS认证，认证通过后返回TGT<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9Akerbaros/1_AS.png" alt="图片错误"></p><p>第二步：客户端用TGT去TGS获取ST<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9Akerbaros/2_TGS.png" alt="图片错误"></p><p>第三步：客户端用ST获取服务端权限<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9Akerbaros/3_Server.png" alt="图片错误"></p><h3 id="黄金白银票据">黄金白银票据</h3><p>黄金票据：伪造TGT<br>条件：</p><ol><li>域名称（shell net config workstation）</li><li>域的SID值（shell whoami/user）</li><li>重点：域的KRBTGT账号的Hash(isadump::dcsync /domain:test.com /all /csv)</li><li>伪造任意用户名</li></ol><p>白银票据：伪造ST<br>条件：</p><ol><li>域名</li><li>域sid</li><li>目标服务器名</li><li>可利用的服务</li><li>服务账号的NTML Hash</li><li>需要伪造的用户名</li></ol><h3 id="委派攻击">委派攻击</h3><p>非约束性委派：伪造一个客户端获取服务器权限，去执行其他操作</p>]]></content>
      
      
      <categories>
          
          <category> Web安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 安全协议 </tag>
            
            <tag> Kerberos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议（二）：SSL</title>
      <link href="/2024/11/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/"/>
      <url>/2024/11/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/TLS%E5%9B%9B%E6%AC%A1%E5%AF%B9%E8%AF%9D.png" alt="图片错误"><br>Client Hello<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/client_hello.png" alt="图片错误"><br>Server Hello<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/server_hello.png" alt="图片错误"><br>Certificate<br>Server Key Exchange<br>Server Hello Done<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/cer&amp;key_exch&amp;done.png" alt="图片错误"><br>Client Key Exchange<br>Change Ciper Spec<br>Encrypted Handshake Message<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/key_exch&amp;chcipher&amp;enmassage.png" alt="图片错误"><br>Application<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/appdata.png" alt="图片错误"><br>Chrome<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/baidu_ssl.png" alt="图片错误"><br>Edge<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ASSL/baidu_http.png" alt="图片错误"></p>]]></content>
      
      
      <categories>
          
          <category> Web安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 安全协议 </tag>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>渗透笔记（一）：pwn入门</title>
      <link href="/2024/11/13/%E6%B8%97%E9%80%8F%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9Apwn%E5%85%A5%E9%97%A8/"/>
      <url>/2024/11/13/%E6%B8%97%E9%80%8F%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9Apwn%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="可执行文件">可执行文件</h2><h3 id="机器码">机器码</h3><ol><li>地址以字节编码表示：1 Byte = 8 bits</li><li>常以16进制表示：0x3c = 0011 1100</li></ol><h2 id="程序运行">程序运行</h2><h3 id="虚拟内存">虚拟内存</h3><ol><li>虚拟内存用户空间每个进程一份</li><li>虚拟内存内核空间所有进程共享一份</li><li>虚拟内存mmap段中的动态链接库仅在物理内存中装载一份</li></ol><p><img src="pic/%E6%B8%97%E9%80%8F%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9Apwn%E5%85%A5%E9%97%A8/32%E4%BD%8D%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png" alt="图片错误"></p><p><img src="pic/%E6%B8%97%E9%80%8F%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9Apwn%E5%85%A5%E9%97%A8/64%E4%BD%8D%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png" alt="图片错误"></p><h4 id="段（segment）与节（section）">段（segment）与节（section）</h4><ol><li>一个段包括多个节</li><li>段视图用于进程的内存区域的rwx权限划分</li><li>节视图用于ELF文件编译链接时 与 在磁盘上存储时的文件结构的组织</li></ol><ul><li>代码段（Text Segment）包含了代码与只读数据<ul><li>.text节</li><li>.plt节</li></ul></li><li>数据段（Data Segment）包含了可读可写数据<ul><li>.got.plt节</li><li>.bss节</li></ul></li><li>栈段（Stack Segment）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 二进制安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PWN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议（一）：IPSec</title>
      <link href="/2024/10/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AIPSec/"/>
      <url>/2024/10/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AIPSec/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>VPN（Virtual Private Network，虚拟专用网）是一种在公用网络上建立专用网络的技术。它之所以称之为虚拟网，主要是因为VPN的两个节点之间并没有像传统专用网那样使用端到端的物理链路，而是架构在公用网络如Internet之上的逻辑网络，用户数据通过逻辑链路传输。</p><p>IPsec（Internet Protocol Security）是为IP网络提供安全性的协议和服务的集合，它是VPN（Virtual Private Network，虚拟专用网）中常用的一种技术。 由于IP报文本身没有集成任何安全特性，IP数据包在公用网络如Internet中传输可能会面临被伪造、窃取或篡改的风险。通信双方通过IPsec建立一条IPsec隧道，IP数据包通过IPsec隧道进行加密传输，有效保证了数据在不安全的网络环境如Internet中传输的安全性。</p><p>IPsec VPN是指采用IPsec实现远程接入的一种VPN技术，通过在公网上为两个或多个私有网络之间建立IPsec隧道，并通过加密和验证算法保证VPN连接的安全。</p><p>IPsec VPN保护的是点对点之间的通信，通过IPsec VPN可以在主机和主机之间、主机和网络安全网关之间或网络安全网关（如路由器、防火墙）之间建立安全的隧道连接。其协议主要工作在IP层，在IP层对数据包进行加密和验证。</p><p>相对于其他VPN技术，IPsec VPN安全性更高，数据在IPsec隧道中都是加密传输，但相应的IPsec VPN在配置和组网部署上更复杂。</p><h2 id="步骤">步骤</h2><ol><li><p>识别“感兴趣流”。网络设备接收到报文后，通常会将报文的五元组等信息和IPsec策略进行匹配来判断报文是否要通过IPsec隧道传输，需要通过IPsec隧道传输的流量通常被称为“感兴趣流”。</p></li><li><p>协商安全联盟（Security Association，以下简称SA）。SA是通信双方对某些协商要素的约定，比如双方使用的安全协议、数据传输采用的封装模式、协议采用的加密和验证算法、用于数据传输的密钥等，通信双方之间只有建立了SA，才能进行安全的数据传输。<br>识别出感兴趣流后，本端网络设备会向对端网络设备发起SA协商。在这一阶段，通信双方之间通过IKE协议先协商建立IKE SA（用于身份验证和密钥信息交换），然后在IKE SA的基础上协商建立IPsec SA（用于数据安全传输）。</p></li><li><p>数据传输。IPsec SA建立成功后，双方就可以通过IPsec隧道传输数据了。<br>IPsec为了保证数据传输的安全性，在这一阶段需要通过AH或ESP协议对数据进行加密和验证。加密机制保证了数据的机密性，防止数据在传输过程中被窃取；验证机制保证了数据的真实可靠，防止数据在传输过程中被仿冒和篡改。<br>如图所示，IPsec发送方会使用加密算法和加密密钥对报文进行加密，即将原始数据“乔装打扮”封装起来。然后发送方和接收方分别通过相同的验证算法和验证密钥对加密后的报文进行处理得到完整性校验值ICV。如果两端计算的ICV相同则表示该报文在传输过程中没有被篡改，接收方对验证通过的报文进行解密处理；如果ICV不相同则直接丢弃报文。<br><img src="pic/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AIPSec/IPSec%E8%BF%87%E7%A8%8B.png" alt="图片错误"></p></li><li><p>隧道拆除。通常情况下，通信双方之间的会话老化（连接断开）即代表通信双方数据交换已经完成，因此为了节省系统资源，通信双方之间的隧道在空闲时间达到一定值后会自动删除。</p></li></ol><h2 id="IPsec的3个重要协议-IKE-AH-ESP">IPsec的3个重要协议- IKE/AH/ESP</h2><h3 id="IKE（Internet-Key-Exchange，因特网密钥交换）">IKE（Internet Key Exchange，因特网密钥交换）</h3><p>IKE协议是一种基于UDP的应用层协议，它主要用于SA协商和密钥管理。</p><p>IKE协议分IKEv1和IKEv2两个版本，IKEv2与IKEv1相比，修复了多处公认的密码学方面的安全漏洞，提高了安全性能，同时简化了安全联盟的协商过程，提高了协商效率。</p><p>IKE协议属于一种混合型协议，它综合了ISAKMP（Internet Security Association and Key Management Protocol）、Oakley协议和SKEME协议这三个协议。其中，ISAKMP定义了IKE SA的建立过程，Oakley和SKEME协议的核心是DH（Diffie-Hellman）算法，主要用于在Internet上安全地分发密钥、验证身份，以保证数据传输的安全性。IKE SA和IPsec SA需要的加密密钥和验证密钥都是通过DH算法生成的，它还支持密钥动态刷新。</p><h3 id="AH（Authentication-Header，认证头）">AH（Authentication Header，认证头）</h3><p>AH协议用来对IP报文进行数据源认证和完整性校验，即用来保证传输的IP报文的来源可信和数据不被篡改，但它并不提供加密功能。AH协议在每个数据包的标准IP报文头后面添加一个AH报文头，AH协议对报文的完整性校验的范围是整个IP报文。</p><h3 id="ESP（Encapsulating-Security-Payload，封装安全载荷）">ESP（Encapsulating Security Payload，封装安全载荷）</h3><p>ESP协议除了对IP报文进行数据源认证和完整性校验以外，还能对数据进行加密。ESP协议在每一个数据包的标准IP报头后方添加一个ESP报文头，并在数据包后方追加一个ESP尾（ESP Trailer和ESP Auth data）。ESP协议在传输模式下的数据完整性校验范围不包括IP头，因此它不能保证IP报文头不被篡改。</p><p>AH和ESP可以单独使用，也可以同时使用。AH和ESP同时使用时，报文会先进行ESP封装，再进行AH封装；IPsec解封装时，先进行AH解封装，再进行ESP解封装。</p><h3 id="IPsec使用的端口">IPsec使用的端口</h3><p>IPsec中IKE协议采用UDP 500端口发起和响应协商，因此为了使IKE协商报文顺利通过网关设备，通常要在网关设备上配置安全策略放开UDP 500端口。另外，在IPsec NAT穿越场景下，还需要放开UDP 4500端口。</p><p>而AH和ESP属于网络层协议，不涉及端口。为了使IPsec隧道能正常建立，通常还要在网关设备上配置安全策略放开AH（IP协议号是51）和ESP（IP协议号是50）服务。</p><h3 id="IPsec-VPN和SSL-VPN对比">IPsec VPN和SSL VPN对比</h3><p>IPsec和SSL是部署VPN时最常用的两种技术，它们都有加密和验证机制保证用户远程接入的安全性。从以下几个方面对IPsec VPN和SSL VPN进行对比：<br>OSI参考模型工作层级<br>OSI定义了网络互连的七层框架：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。IPsec工作在网络层，它直接运行在IP（Internet Protocol，互联网协议）之上。而SSL工作在应用层，是一种应用层协议，它加密的是HTTP流量，而不是直接加密IP数据包。</p><h4 id="配置部署">配置部署</h4><p>IPsec VPN通常适用于Site to Site（站点到站点）的组网，要求站点分别部署VPN网关或远程用户安装专用的VPN客户端，因此配置部署复杂度和维护成本都比较高。但SSL VPN通常适用于Client to Site（客户端到站点）的组网，只要求远程用户使用支持SSL的标准浏览器安装指定插件即可进行访问，通过数据中心部署VPN网关进行集中管理和维护，因此配置部署更简单，维护成本相对较低。</p><h4 id="安全性">安全性</h4><p>IPsec工作在网络层，对站点间传输的所有数据进行保护。IPsec VPN要求远程用户安装专用的VPN客户端或在站点部署VPN网关设备，用户访问会受到客户端或网关在用户认证规则、安全策略规则或内容安全过滤方面的检查，因此安全性更高。而SSL VPN不要求安装专用客户端或接入站点部署网关设备，更容易受到安全威胁的影响。</p><h4 id="访问控制">访问控制</h4><p>IPsec工作在网络层，不能基于应用进行细粒度的访问控制。而SSL VPN在精细化访问控制上更灵活，网络管理员可以将网络资源根据不同的应用类型划分为不同的资源类型，每一类资源的访问权限不同。</p>]]></content>
      
      
      <categories>
          
          <category> Web安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 安全协议 </tag>
            
            <tag> IPSec </tag>
            
            <tag> VPN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
